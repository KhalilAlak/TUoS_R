as.matrix(binomial_train_dtm),
binomial_train_labels,
family = 'binomial'
)
library(tm)
library(glmnet)
library(SnowballC)
library(tidyverse)
topic_docs <- Corpus(
DirSource(
"20news-train/comp.graphics",
encoding='UTF-8'
)
)
summary(topic_docs[1:5])
inspect(topic_docs[[1]])
topic_docs[[1]]$meta
topic_docs[[1]]$content
topic_2_docs <- Corpus(
DirSource(
"20news-train/rec.motorcycles",
encoding='UTF-8'
)
)
binomial_docs <- c(
as.list(topic_docs),
as.list(topic_2_docs)
)
labels_1 <- replicate(length(topic_docs), 'comp.graphics')
labels_2 <- replicate(length(topic_2_docs), 'rec.motorcycles')
binomial_labels <- c(labels_1, labels_2)
length(binomial_docs) == length(binomial_labels)
example_doc <- binomial_docs[["38487"]]
print(example_doc)
tokens <- Boost_tokenizer(example_doc)
summary(tokens)
#Execise 1
tokens <- MC_tokenizer(example_doc)
summary(tokens)
view(tokens)
removePunctuation(example_doc)
removePunctuation(tokens)
stops <- stopwords('en')
print(stops)
removeWords(example_doc, stops)
tolower(example_doc)
removeWords(
tolower(example_doc),
stops
)
#Execise 2
tokens <- strsplit(example_doc, "\\s+")[[1]]
print(tokens[1:20])
tokens_lower <- tolower(tokens)
library(tm)
stops <- stopwords("en")
tokens_clean <- removeWords(tokens_lower, stops)
print(tokens_clean[1:20])
removeWords(
tolower(tokens),
stops
)
stemDocument(
example_doc
)
text_lower <- tolower(example_doc)
text_nopunct <- removePunctuation(text_lower)
stops <- stopwords("en")
text_nostop <- removeWords(text_nopunct, stops)
text_stemmed <- stemDocument(text_nostop)
print(text_stemmed)
binomial_docs <- Corpus(
VectorSource(binomial_docs)
)
binomial_docs
# Start with lowercasing
cleaned_binomial_docs <- tm_map(
binomial_docs, # the collection of documents to process
tolower # the function to apply to each document
)
cleaned_binomial_docs$content[1] # view the document - are they in lowercase now?
cleaned_binomial_docs$content[1]
# Then remove punctuation
cleaned_binomial_docs <- tm_map(
cleaned_binomial_docs, # we want to stack on top of the previous preprocessing!
removePunctuation # the function to apply to each document
)
cleaned_binomial_docs$content[1] # have all punctuations been removed?
# Then remove stopwords
cleaned_binomial_docs <- tm_map(
cleaned_binomial_docs,
removeWords, # the function to apply to each document
stopwords('en') # additional argument to specify the stopwords to be removed
)
cleaned_binomial_docs$content[1] # have the stopwords been removed?
# And finally stem
cleaned_binomial_docs <- tm_map(
cleaned_binomial_docs,
stemDocument
)
cleaned_binomial_docs$content[1] # have the words been stemmed?
binomial_dtm <- DocumentTermMatrix(
cleaned_binomial_docs
)
binomial_dtm
#Execise 4
binomial_dtm <- DocumentTermMatrix(cleaned_binomial_docs)
original_dtm <- DocumentTermMatrix(binomial_docs)
original_dtm
inspect(binomial_dtm[1:3,])
doc_lengths <- lapply( # applies a function across each element of a list
as.list(cleaned_binomial_docs),
nchar # count the length of a string
)
doc_lengths <- unlist(doc_lengths) # get rid of the structure that lapply() creates
quantile(doc_lengths)
binomial_dtm_binary <- DocumentTermMatrix(
cleaned_binomial_docs,
control=list(
weighting=weightBin
)
)
inspect(binomial_dtm_binary[1:3,])
binomial_dtm_tfidf <- DocumentTermMatrix(
cleaned_binomial_docs,
control=list(
weighting=weightTfIdf
)
)
inspect(binomial_dtm_tfidf[1:3,])
removeSparseTerms(binomial_dtm, 0.98)
#Execise 5
library(tm)
corpus <- cleaned_binomial_docs
dtm <- DocumentTermMatrix(corpus)
dtm
dtm_sparse <- removeSparseTerms(dtm, 0.98)
dtm_sparse
removeSparseTerms(dtm, sparse = 0.95)
binomial_dtm
ncol(removeSparseTerms(binomial_dtm, 0.99))   # threshold = 0.99
ncol(removeSparseTerms(binomial_dtm, 0.98))   # threshold = 0.98
ncol(removeSparseTerms(binomial_dtm, 0.95))   # threshold = 0.95
ncol(removeSparseTerms(binomial_dtm, 0.90))   # threshold = 0.90
ncol(removeSparseTerms(binomial_dtm, 0.80))   # threshold = 0.80
binomial_dtm
binomial_train_dtm
dim(binomial_train_dtm)
observed_vocabulary <- Terms(binomial_dtm)
observed_vocabulary <- binomial_dtm$dimnames$Terms
length(observed_vocabulary)
binomial_train_dtm <- DocumentTermMatrix(
cleaned_binomial_docs,
control = list(dictionary = observed_vocabulary)
)
binomial_model <- glmnet(
as.matrix(binomial_train_dtm),
binomial_train_labels,
family = 'binomial'
)
pic_1_test_docs <- Corpus(
DirSource(
'20news-test/comp.graphics',
encoding='UTF-8'
)
)
topic_2_test_docs <- Corpus(
DirSource(
'20news-test/rec.motorcycles',
encoding='UTF-8'
)
)
binomial_test_docs <- c(
as.list(topic_1_test_docs),
as.list(topic_2_test_docs)
)
topic_1_test_docs <- Corpus(
DirSource(
'20news-test/comp.graphics',
encoding='UTF-8'
)
)
topic_2_test_docs <- Corpus(
DirSource(
'20news-test/rec.motorcycles',
encoding='UTF-8'
)
)
binomial_test_docs <- c(
as.list(topic_1_test_docs),
as.list(topic_2_test_docs)
)
binomial_test_docs <- Corpus(VectorSource(binomial_test_docs))
labels_test_1 <- replicate(length(topic_1_test_docs), 'comp.graphics')
labels_test_2 <- replicate(length(topic_2_test_docs), 'rec.motorcycles')
binomial_test_labels <- c(labels_test_1, labels_test_2)
cleaned_binomial_test_docs <- tm_map(binomial_test_docs, tolower)
cleaned_binomial_test_docs <- tm_map(cleaned_binomial_test_docs, removePunctuation)
cleaned_binomial_test_docs <- tm_map(cleaned_binomial_test_docs, removeWords,
stopwords('en'))
cleaned_binomial_test_docs <- tm_map(cleaned_binomial_test_docs, stemDocument)
binomial_test_dtm <- DocumentTermMatrix(
cleaned_binomial_test_docs,
control=list(
dictionary=observed_vocabulary
)
)
binomial_test_dtm <- data.matrix(binomial_test_dtm)
binomial_probabilities <- predict(
binomial_model,
binomial_test_dtm,
s=tail(binomial_model$lambda, 1),
type='response'
)
binomial_predictions <- ifelse(
binomial_probabilities>0.5,
1,
0
)
inomial_test_labels <- (
binomial_test_labels == 'comp.graphics'
) * 1
binomial_predictions != binomial_test_labels
on_error <- mean(
binomial_predictions != binomial_test_labels
)
print(paste('Accuracy',1-binomial_classification_error))
on_error <- mean(
binomial_predictions != binomial_test_labels)
print(paste('Accuracy',1-binomial_classification_error))
inomial_test_labels <- (
binomial_test_labels == 'comp.graphics'
) * 1
on_error <- mean(
binomial_predictions != binomial_test_labels)
print(paste('Accuracy',1-binomial_classification_error))
cleaned_binomial_test_docs <- tm_map(cleaned_binomial_test_docs, removePunctuation)
cleaned_binomial_test_docs <- tm_map(cleaned_binomial_test_docs, removeWords,
stopwords('en'))
cleaned_binomial_test_docs <- tm_map(cleaned_binomial_test_docs, stemDocument)
binomial_test_dtm <- DocumentTermMatrix(
cleaned_binomial_test_docs,
control=list(
dictionary=observed_vocabulary
)
)
binomial_test_dtm <- data.matrix(binomial_test_dtm)
binomial_probabilities <- predict(
binomial_model,
binomial_test_dtm,
s=tail(binomial_model$lambda, 1),
type='response'
)
binomial_predictions <- ifelse(
binomial_probabilities>0.5,
1,
0
)
inomial_test_labels <- (
binomial_test_labels == 'comp.graphics'
) * 1
binomial_test_labels <- (
binomial_test_labels == 'comp.graphics'
) * 1
binomial_test_docs <- c(
as.list(topic_1_test_docs),
as.list(topic_2_test_docs)
)
binomial_test_docs <- Corpus(VectorSource(binomial_test_docs))
labels_test_1 <- replicate(length(topic_1_test_docs), 'comp.graphics')
labels_test_2 <- replicate(length(topic_2_test_docs), 'rec.motorcycles')
binomial_test_labels <- c(labels_test_1, labels_test_2)
cleaned_binomial_test_docs <- tm_map(binomial_test_docs, tolower)
cleaned_binomial_test_docs <- tm_map(cleaned_binomial_test_docs, removePunctuation)
cleaned_binomial_test_docs <- tm_map(cleaned_binomial_test_docs, removeWords,
stopwords('en'))
cleaned_binomial_test_docs <- tm_map(cleaned_binomial_test_docs, stemDocument)
binomial_test_dtm <- DocumentTermMatrix(
cleaned_binomial_test_docs,
control=list(
dictionary=observed_vocabulary
)
)
binomial_test_dtm <- data.matrix(binomial_test_dtm)
binomial_probabilities <- predict(
binomial_model,
binomial_test_dtm,
s=tail(binomial_model$lambda, 1),
type='response'
)
binomial_predictions <- ifelse(
binomial_probabilities>0.5,
1,
0
)
binomial_test_labels <- (
binomial_test_labels == 'comp.graphics'
) * 1
binomial_classification_error <- mean(
binomial_predictions != binomial_test_labels)
print(paste('Accuracy',1-binomial_classification_error))
#Execise 6
binomial_dtm_binary <- DocumentTermMatrix(
cleaned_binomial_docs,
control = list(weighting = weightBin)
)
binomial_dtm_tfidf <- DocumentTermMatrix(
cleaned_binomial_docs,
control = list(weighting = weightTfIdf)
)
dim(binomial_dtm_binary)
dim(binomial_dtm_tfidf)
binomial_train_dtm_binary <- DocumentTermMatrix(
cleaned_binomial_docs,
control = list(
dictionary = observed_vocabulary,
weighting = weightBin
)
)
binomial_train_dtm_tfidf <- DocumentTermMatrix(
cleaned_binomial_docs,
control = list(
dictionary = observed_vocabulary,
weighting = weightTfIdf
)
)
binomial_model_binary <- glmnet(
as.matrix(binomial_train_dtm_binary),
binomial_train_labels,
family = 'binomial'
)
binomial_model_tfidf <- glmnet(
as.matrix(binomial_train_dtm_tfidf),
binomial_train_labels,
family = 'binomial'
)
binomial_test_dtm_binary <- DocumentTermMatrix(
cleaned_binomial_test_docs,
control = list(
dictionary = observed_vocabulary,
weighting = weightBin
)
)
binomial_test_dtm_tfidf <- DocumentTermMatrix(
cleaned_binomial_test_docs,
control = list(
dictionary = observed_vocabulary,
weighting = weightTfIdf
)
)
binomial_test_dtm_binary <- data.matrix(binomial_test_dtm_binary)
binomial_test_dtm_tfidf <- data.matrix(binomial_test_dtm_tfidf)
# Predict probabilities
binomial_probabilities_binary <- predict(
binomial_model_binary,
binomial_test_dtm_binary,
s = tail(binomial_model_binary$lambda, 1),
type = 'response'
)
binomial_probabilities_tfidf <- predict(
binomial_model_tfidf,
binomial_test_dtm_tfidf,
s = tail(binomial_model_tfidf$lambda, 1),
type = 'response'
)
# Convert probabilities to 0/1 predictions
binomial_predictions_binary <- ifelse(binomial_probabilities_binary > 0.5, 1, 0)
binomial_predictions_tfidf <- ifelse(binomial_probabilities_tfidf > 0.5, 1, 0)
# Compute accuracy
error_binary <- mean(binomial_predictions_binary != binomial_test_labels)
error_tfidf <- mean(binomial_predictions_tfidf != binomial_test_labels)
cat("Accuracy (Binary):", 1 - error_binary, "\n")
cat("Accuracy (TF-IDF):", 1 - error_tfidf, "\n")
binomial_dtm_reduced <- removeSparseTerms(binomial_dtm, 0.98)
dim(binomial_dtm_reduced)
reduced_vocabulary <- Terms(binomial_dtm_reduced)
length(reduced_vocabulary)
# Training DTM
binomial_train_dtm_reduced <- DocumentTermMatrix(
cleaned_binomial_docs,
control = list(dictionary = reduced_vocabulary)
)
# Test DTM (must use the same vocabulary!)
binomial_test_dtm_reduced <- DocumentTermMatrix(
cleaned_binomial_test_docs,
control = list(dictionary = reduced_vocabulary)
)
# Convert to matrices for glmnet
binomial_train_matrix_reduced <- as.matrix(binomial_train_dtm_reduced)
binomial_test_matrix_reduced <- as.matrix(binomial_test_dtm_reduced)
binomial_model_reduced <- glmnet(
binomial_train_matrix_reduced,
binomial_train_labels,
family = 'binomial'
)
binomial_probabilities_reduced <- predict(
binomial_model_reduced,
binomial_test_matrix_reduced,
s = tail(binomial_model_reduced$lambda, 1),
type = 'response'
)
binomial_predictions_reduced <- ifelse(binomial_probabilities_reduced > 0.5, 1, 0)
# Calculate accuracy
error_reduced <- mean(binomial_predictions_reduced != binomial_test_labels)
cat("Accuracy (after removing sparse terms):", 1 - error_reduced, "\n")
#Execise 8
# Use the raw corpus (no lowercasing, no stopword removal, no stemming)
binomial_dtm_original <- DocumentTermMatrix(binomial_docs)
# Check dimensions (number of documents and unique words)
dim(binomial_dtm_original)
original_vocabulary <- Terms(binomial_dtm_original)
# Training DTM
binomial_train_dtm_original <- DocumentTermMatrix(
binomial_docs,
control = list(dictionary = original_vocabulary)
)
# Test DTM (must use same vocabulary!)
binomial_test_dtm_original <- DocumentTermMatrix(
binomial_test_docs,
control = list(dictionary = original_vocabulary)
)
# Test DTM (must use same vocabulary!)
binomial_test_dtm_original <- DocumentTermMatrix(
binomial_test_docs,
control = list(dictionary = original_vocabulary)
)
binomial_model_original <- glmnet(
as.matrix(binomial_train_dtm_original),
binomial_train_labels,
family = 'binomial'
)
binomial_probabilities_original <- predict(
binomial_model_original,
as.matrix(binomial_test_dtm_original),
s = tail(binomial_model_original$lambda, 1),
type = 'response'
)
binomial_predictions_original <- ifelse(binomial_probabilities_original > 0.5, 1, 0)
error_original <- mean(binomial_predictions_original != binomial_test_labels)
cat("Accuracy (non-preprocessed text):", 1 - error_original, "\n")
cleaned_topic_docs <- tm_map(topic_docs, tolower)
cleaned_topic_docs <- tm_map(cleaned_topic_docs, removePunctuation)
cleaned_topic_docs <- tm_map(cleaned_topic_docs, removeWords, stopwords('en
'))
cleaned_topic_docs <- tm_map(cleaned_topic_docs, removeWords, stopwords('en'))
topic_dtm <- DocumentTermMatrix(cleaned_topic_docs)
findFreqTerms(
topic_dtm,
lowfreq=100
)
findAssocs(
topic_dtm,
'software',
corlimit=0.75 # the correlation limit (between 0 and 1)
)
#Further Exercise 1
graphics_docs <- Corpus(DirSource("20news-train/comp.graphics"))
motor_docs <- Corpus(DirSource("20news-train/rec.motorcycles"))
View(ial_train_dtm)
graphics_clean <- tm_map(graphics_docs, content_transformer(tolower))
graphics_clean <- tm_map(graphics_clean, removePunctuation)
graphics_clean <- tm_map(graphics_clean, removeWords, stopwords("en"))
graphics_clean <- tm_map(graphics_clean, stemDocument)
motor_clean <- tm_map(motor_docs, content_transformer(tolower))
motor_clean <- tm_map(motor_clean, removePunctuation)
motor_clean <- tm_map(motor_clean, removeWords, stopwords("en"))
motor_clean <- tm_map(motor_clean, stemDocument)
graphics_dtm <- DocumentTermMatrix(graphics_clean)
motor_dtm <- DocumentTermMatrix(motor_clean)
findFreqTerms(graphics_dtm, lowfreq = 50)
findFreqTerms(motor_dtm, lowfreq = 50)
graphics_terms <- findFreqTerms(graphics_dtm, lowfreq = 50)
motor_terms <- findFreqTerms(motor_dtm, lowfreq = 50)
common_terms <- intersect(graphics_terms, motor_terms)
common_terms
findAssocs(graphics_dtm, "file", 0.2)
findAssocs(motor_dtm, "file", 0.2)
#Further Exercise 2
space_docs <- Corpus(DirSource("20news-train/sci.space"))
guns_docs <- Corpus(DirSource("20news-train/talk.politics.guns"))
combined_docs <- c(as.list(space_docs), as.list(guns_docs))
combined_corpus <- Corpus(VectorSource(combined_docs))
labels <- c(rep("sci.space", length(space_docs)), rep("talk.politics.guns", length(guns_docs)))
cleaned <- tm_map(combined_corpus, content_transformer(tolower))
cleaned <- tm_map(cleaned, removePunctuation)
cleaned <- tm_map(cleaned, removeWords, stopwords("en"))
cleaned <- tm_map(cleaned, stemDocument)
dtm <- DocumentTermMatrix(cleaned)
labels_bin <- (labels == "sci.space") * 1
model <- glmnet(as.matrix(dtm), labels_bin, family = "binomial")
#Further Exercise 3
findFreqTerms(dtm_space, 40)
#Further Exercise 3
space_docs <- Corpus(DirSource("20news-train/sci.space"))
guns_docs  <- Corpus(DirSource("20news-train/talk.politics.guns"))
corpus <- tm_map(corpus, content_transformer(tolower))
clean_corpus <- function(corpus) {
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, stopwords("en"))
corpus <- tm_map(corpus, stemDocument)
return(corpus)
}
space_clean <- clean_corpus(space_docs)
guns_clean  <- clean_corpus(guns_docs)
dtm_space <- DocumentTermMatrix(space_clean)
dtm_guns  <- DocumentTermMatrix(guns_clean)
findFreqTerms(dtm_space, 40)
findFreqTerms(dtm_guns, 40)
findAssocs(dtm_space, "space", 0.3)
findAssocs(dtm_guns, "gun", 0.3)
